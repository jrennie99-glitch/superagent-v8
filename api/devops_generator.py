"""
Enterprise DevOps Generator
Generates CI/CD pipelines, tests, monitoring, and deployment configurations
"""
import os
from typing import Dict, List, Any
import google.generativeai as genai


class DevOpsGenerator:
    """Generates enterprise DevOps configurations"""
    
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-2.0-flash')
        else:
            self.model = None
    
    async def generate_pytest_tests(self, entities: List[str]) -> str:
        """Generate Pytest test suite"""
        
        tests = '''"""
Test Suite
Generated by SuperAgent Enterprise
"""
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# from main import app
# from models import Base

# Test database setup
SQLALCHEMY_TEST_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_TEST_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

@pytest.fixture
def db():
    """Create test database"""
    Base.metadata.create_all(bind=engine)
    yield TestingSessionLocal()
    Base.metadata.drop_all(bind=engine)

@pytest.fixture
def client():
    """Create test client"""
    return TestClient(app)

class TestHealth:
    """Health check tests"""
    
    def test_health_check(self, client):
        """Test health endpoint"""
        response = client.get("/health")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"

'''
        
        for entity in entities:
            entity_lower = entity.lower()
            entity_plural = f"{entity_lower}s"
            
            tests += f'''
class Test{entity}:
    """Tests for {entity} endpoints"""
    
    def test_list_{entity_plural}(self, client):
        """Test listing {entity_plural}"""
        response = client.get("/api/v1/{entity_plural}")
        assert response.status_code == 200
        assert isinstance(response.json(), list)
    
    def test_create_{entity_lower}(self, client):
        """Test creating {entity_lower}"""
        payload = {{"name": "Test {entity}"}}
        response = client.post("/api/v1/{entity_plural}", json=payload)
        assert response.status_code == 201
        assert response.json()["name"] == "Test {entity}"
    
    def test_get_{entity_lower}(self, client):
        """Test getting {entity_lower} by ID"""
        # First create
        payload = {{"name": "Test {entity}"}}
        create_response = client.post("/api/v1/{entity_plural}", json=payload)
        item_id = create_response.json()["id"]
        
        # Then get
        response = client.get(f"/api/v1/{entity_plural}/{{item_id}}")
        assert response.status_code == 200
        assert response.json()["id"] == item_id
    
    def test_update_{entity_lower}(self, client):
        """Test updating {entity_lower}"""
        # Create
        payload = {{"name": "Test {entity}"}}
        create_response = client.post("/api/v1/{entity_plural}", json=payload)
        item_id = create_response.json()["id"]
        
        # Update
        update_payload = {{"name": "Updated {entity}"}}
        response = client.put(f"/api/v1/{entity_plural}/{{item_id}}", json=update_payload)
        assert response.status_code == 200
        assert response.json()["name"] == "Updated {entity}"
    
    def test_delete_{entity_lower}(self, client):
        """Test deleting {entity_lower}"""
        # Create
        payload = {{"name": "Test {entity}"}}
        create_response = client.post("/api/v1/{entity_plural}", json=payload)
        item_id = create_response.json()["id"]
        
        # Delete
        response = client.delete(f"/api/v1/{entity_plural}/{{item_id}}")
        assert response.status_code == 204

'''
        
        return tests
    
    async def generate_github_actions_workflow(self) -> str:
        """Generate GitHub Actions CI/CD workflow"""
        
        workflow = """name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install linting tools
        run: |
          pip install flake8 black isort mypy
      
      - name: Run Black
        run: black --check .
      
      - name: Run isort
        run: isort --check-only .
      
      - name: Run Flake8
        run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
      
      - name: Run MyPy
        run: mypy . --ignore-missing-imports

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      
      - name: Run tests with coverage
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
        run: |
          pytest tests/ --cov=api --cov-report=xml --cov-report=html
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          fail_ci_if_error: true

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install security tools
        run: |
          pip install bandit safety
      
      - name: Run Bandit
        run: bandit -r api/ -f json -o bandit-report.json || true
      
      - name: Check dependencies
        run: safety check --json || true

  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [test, security]
    permissions:
      contents: read
      packages: write
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Log in to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha
      
      - name: Build and push backend
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./Dockerfile.backend
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
      
      - name: Build and push frontend
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}-frontend
          labels: ${{ steps.meta.outputs.labels }}

  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to production
        env:
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
          DEPLOY_HOST: ${{ secrets.DEPLOY_HOST }}
          DEPLOY_USER: ${{ secrets.DEPLOY_USER }}
        run: |
          mkdir -p ~/.ssh
          echo "$DEPLOY_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H $DEPLOY_HOST >> ~/.ssh/known_hosts
          ssh -i ~/.ssh/deploy_key $DEPLOY_USER@$DEPLOY_HOST 'cd /app && docker-compose pull && docker-compose up -d'
      
      - name: Notify deployment
        run: echo "âœ… Deployment to production completed"
"""
        
        return workflow
    
    async def generate_monitoring_config(self) -> str:
        """Generate Prometheus monitoring configuration"""
        
        config = """global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    monitor: 'app-monitor'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

rule_files:
  - 'alert_rules.yml'

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
"""
        
        return config
    
    async def generate_alert_rules(self) -> str:
        """Generate Prometheus alert rules"""
        
        rules = """groups:
  - name: app_alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      - alert: HighLatency
        expr: histogram_quantile(0.95, http_request_duration_seconds) > 1
        for: 5m
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is {{ $value }}s"

      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        annotations:
          summary: "Database is down"
          description: "PostgreSQL database is not responding"

      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        annotations:
          summary: "Redis cache is down"
          description: "Redis cache is not responding"

      - alert: HighMemoryUsage
        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
        for: 5m
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }}"

      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) > 0.8
        for: 5m
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value | humanizePercentage }}"
"""
        
        return rules
    
    async def generate_deployment_guide(self) -> str:
        """Generate deployment guide"""
        
        guide = """# Deployment Guide

## Prerequisites
- Docker and Docker Compose installed
- PostgreSQL 15+
- Redis 7+
- Node.js 18+
- Python 3.11+

## Local Development

1. **Clone repository**
   ```bash
   git clone <repository-url>
   cd app
   ```

2. **Set up environment**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

3. **Start services**
   ```bash
   docker-compose up -d
   ```

4. **Run migrations**
   ```bash
   docker-compose exec backend alembic upgrade head
   ```

5. **Access application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Docs: http://localhost:8000/docs

## Production Deployment

### AWS Deployment

1. **Create ECS cluster**
   ```bash
   aws ecs create-cluster --cluster-name app-cluster
   ```

2. **Create task definitions**
   ```bash
   aws ecs register-task-definition --cli-input-json file://task-definition.json
   ```

3. **Create service**
   ```bash
   aws ecs create-service --cluster app-cluster --service-name app-service --task-definition app-task:1 --desired-count 2
   ```

### Kubernetes Deployment

1. **Create namespace**
   ```bash
   kubectl create namespace app
   ```

2. **Apply configurations**
   ```bash
   kubectl apply -f k8s/
   ```

3. **Check deployment**
   ```bash
   kubectl get pods -n app
   ```

### Railway Deployment

1. **Connect GitHub repository**
2. **Add environment variables**
3. **Deploy**
   ```bash
   railway up
   ```

## Monitoring

1. **Access Prometheus**
   - URL: http://localhost:9090

2. **Access Grafana**
   - URL: http://localhost:3001
   - Default credentials: admin/admin

3. **View logs**
   ```bash
   docker-compose logs -f backend
   ```

## Backup & Recovery

1. **Backup database**
   ```bash
   docker-compose exec postgres pg_dump -U postgres app_db > backup.sql
   ```

2. **Restore database**
   ```bash
   docker-compose exec -T postgres psql -U postgres app_db < backup.sql
   ```

## Troubleshooting

- Check logs: `docker-compose logs <service>`
- Restart service: `docker-compose restart <service>`
- Rebuild image: `docker-compose build --no-cache <service>`
"""
        
        return guide
    
    async def generate_complete_devops(self, entities: List[str]) -> Dict[str, Any]:
        """Generate complete DevOps configuration"""
        
        return {
            "success": True,
            "pytest_tests": await self.generate_pytest_tests(entities),
            "github_actions_workflow": await self.generate_github_actions_workflow(),
            "prometheus_config": await self.generate_monitoring_config(),
            "alert_rules": await self.generate_alert_rules(),
            "deployment_guide": await self.generate_deployment_guide(),
            "files_to_create": {
                "tests": {
                    "test_api.py": await self.generate_pytest_tests(entities),
                    "conftest.py": "# Pytest configuration"
                },
                "ci_cd": {
                    ".github/workflows/ci-cd.yml": await self.generate_github_actions_workflow()
                },
                "monitoring": {
                    "prometheus.yml": await self.generate_monitoring_config(),
                    "alert_rules.yml": await self.generate_alert_rules()
                },
                "docs": {
                    "DEPLOYMENT.md": await self.generate_deployment_guide()
                }
            }
        }


# Global instance
devops_generator = DevOpsGenerator()
