"""
Enterprise Schema Designer
Generates database schemas, migrations, and ORM models from requirements
"""
import os
import json
from typing import Dict, List, Any, Optional
import google.generativeai as genai


class SchemaDesigner:
    """Designs and generates database schemas"""
    
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-2.0-flash')
        else:
            self.model = None
    
    async def design_schema(self, requirements: str, entities: List[str]) -> Dict[str, Any]:
        """Design database schema based on requirements and entities"""
        
        if not self.model:
            return {"error": "AI model not configured"}
        
        entities_str = ", ".join(entities)
        
        prompt = f"""Design a production-ready PostgreSQL database schema for:

REQUIREMENTS: {requirements}
ENTITIES: {entities_str}

Return a comprehensive schema design in JSON:
{{
    "tables": [
        {{
            "name": "table_name",
            "columns": [
                {{"name": "id", "type": "BIGSERIAL PRIMARY KEY"}},
                {{"name": "field_name", "type": "VARCHAR(255)", "nullable": false, "unique": false}},
                {{"name": "created_at", "type": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP"}}
            ],
            "indexes": ["idx_field_name"],
            "constraints": ["FOREIGN KEY (user_id) REFERENCES users(id)"]
        }}
    ],
    "relationships": [
        {{"from": "users", "to": "posts", "type": "one-to-many", "foreign_key": "user_id"}},
        {{"from": "posts", "to": "comments", "type": "one-to-many", "foreign_key": "post_id"}}
    ],
    "enums": [
        {{"name": "user_role", "values": ["admin", "user", "moderator"]}}
    ],
    "best_practices": [
        "Use BIGSERIAL for IDs to avoid overflow",
        "Always include created_at and updated_at timestamps",
        "Use indexes on frequently queried columns",
        "Implement soft deletes with deleted_at column"
    ]
}}"""
        
        try:
            response = self.model.generate_content(prompt)
            text = response.text.strip()
            
            # Extract JSON from response
            import re
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            return {"raw_design": text}
        except Exception as e:
            return {"error": str(e)}
    
    async def generate_sql_migration(self, schema: Dict[str, Any]) -> str:
        """Generate SQL migration file from schema"""
        
        migration = "-- Migration: Create initial schema\n"
        migration += "-- Generated by SuperAgent Enterprise\n\n"
        
        # Create enums first
        for enum in schema.get("enums", []):
            enum_values = ', '.join([f"'{v}'" for v in enum['values']])
            migration += f"CREATE TYPE {enum['name']} AS ENUM ({enum_values});\n\n"
        
        # Create tables
        for table in schema.get("tables", []):
            migration += f"CREATE TABLE {table['name']} (\n"
            
            columns = []
            for col in table['columns']:
                col_def = f"  {col['name']} {col['type']}"
                if not col.get('nullable', True):
                    col_def += " NOT NULL"
                if col.get('unique'):
                    col_def += " UNIQUE"
                columns.append(col_def)
            
            migration += ",\n".join(columns)
            
            # Add constraints
            for constraint in table.get('constraints', []):
                migration += f",\n  {constraint}"
            
            migration += "\n);\n\n"
        
        # Create indexes
        for table in schema.get("tables", []):
            for index in table.get('indexes', []):
                table_name = table['name']
                col_name = index.replace('idx_', '')
                migration += f"CREATE INDEX {index} ON {table_name}({col_name});\n"
        
        migration += "\n-- Seed data (optional)\n"
        migration += "-- INSERT INTO users (email, password, role) VALUES ('admin@example.com', 'hashed_password', 'admin');\n"
        
        return migration
    
    async def generate_sqlalchemy_models(self, schema: Dict[str, Any]) -> str:
        """Generate SQLAlchemy ORM models from schema"""
        
        models = """\"\"\"
SQLAlchemy ORM Models
Generated by SuperAgent Enterprise
\"\"\"
from sqlalchemy import Column, Integer, String, DateTime, Boolean, ForeignKey, Enum, Index, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime
import enum

Base = declarative_base()

"""
        
        # Generate enum classes
        for enum_def in schema.get("enums", []):
            models += f"class {enum_def['name'].title()}(enum.Enum):\n"
            for value in enum_def['values']:
                models += f"    {value.upper()} = '{value}'\n"
            models += "\n"
        
        # Generate model classes
        for table in schema.get("tables", []):
            table_name = table['name']
            class_name = ''.join(word.title() for word in table_name.split('_'))
            
            models += f"class {class_name}(Base):\n"
            models += f"    __tablename__ = '{table_name}'\n\n"
            
            # Add columns
            for col in table['columns']:
                col_name = col['name']
                col_type = col['type']
                
                # Map SQL types to SQLAlchemy
                if 'BIGSERIAL' in col_type or 'SERIAL' in col_type:
                    models += f"    {col_name} = Column(Integer, primary_key=True, autoincrement=True)\n"
                elif 'VARCHAR' in col_type:
                    length = 255
                    if '(' in col_type:
                        length = int(col_type.split('(')[1].split(')')[0])
                    models += f"    {col_name} = Column(String({length}))\n"
                elif 'TIMESTAMP' in col_type:
                    models += f"    {col_name} = Column(DateTime, default=datetime.utcnow)\n"
                elif 'BOOLEAN' in col_type:
                    models += f"    {col_name} = Column(Boolean, default=False)\n"
                elif 'TEXT' in col_type:
                    models += f"    {col_name} = Column(Text)\n"
            
            models += "\n    def __repr__(self):\n"
            models += f"        return f'<{class_name}(id={{self.id}})>'\n\n"
        
        return models
    
    async def generate_alembic_migration(self, schema: Dict[str, Any], version: str = "001") -> str:
        """Generate Alembic migration file"""
        
        migration = f'''\"\"\"Create initial schema

Revision ID: {version}
Revises: 
Create Date: 2024-01-01 00:00:00.000000

\"\"\"
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '{version}'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    \"\"\"Upgrade database schema\"\"\"
'''
        
        # Add table creation operations
        for table in schema.get("tables", []):
            migration += f"\n    # Create {table['name']} table\n"
            migration += f"    op.create_table('{table['name']}',\n"
            
            for col in table['columns']:
                col_name = col['name']
                col_type = col['type']
                migration += f"        sa.Column('{col_name}', sa.{col_type}),\n"
            
            migration += "    )\n"
        
        migration += """

def downgrade() -> None:
    \"\"\"Downgrade database schema\"\"\"
"""
        
        # Add table drop operations in reverse order
        for table in reversed(schema.get("tables", [])):
            migration += f"    op.drop_table('{table['name']}')\n"
        
        return migration
    
    async def design_complete_schema(self, requirements: str, entities: List[str]) -> Dict[str, Any]:
        """Complete schema design workflow"""
        
        # Step 1: Design schema
        schema = await self.design_schema(requirements, entities)
        if "error" in schema:
            return schema
        
        # Step 2: Generate SQL migration
        sql_migration = await self.generate_sql_migration(schema)
        
        # Step 3: Generate SQLAlchemy models
        sqlalchemy_models = await self.generate_sqlalchemy_models(schema)
        
        # Step 4: Generate Alembic migration
        alembic_migration = await self.generate_alembic_migration(schema)
        
        return {
            "success": True,
            "schema": schema,
            "sql_migration": sql_migration,
            "sqlalchemy_models": sqlalchemy_models,
            "alembic_migration": alembic_migration,
            "files_to_create": [
                "migrations/versions/001_initial_schema.py",
                "models.py",
                "schema.sql"
            ]
        }


# Global instance
schema_designer = SchemaDesigner()
